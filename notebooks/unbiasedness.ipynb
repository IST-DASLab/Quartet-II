{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=8\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=8\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "from models.quantization.quantizers import QuestMXFP4Quantizer, AlbertTsengQuantizer, EdenSRQuantizer, IsolatedEdenQuantizer, QuestNvfp4Quantizer, Nvfp4Quantizer\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Scales DType | Group Size | Unbiased | MSE, rate-distortion bits | Magnitude Misalignment |\n",
      "|--------------|------------|----------|---------------------------|------------------------|\n",
      "| FP32         | 128        | NO       |                      3.21 |                0.01084 |\n",
      "| FP32         | 128        | SR       |                      2.69 |               -0.00005 |\n",
      "| FP32         | 128        | EDEN     |                      3.22 |                0.00000 |\n",
      "| E4M3         | 16         | NO       |                      3.40 |                0.00793 |\n",
      "| E4M3         | 16         | SR       |                      2.71 |               -0.00001 |\n",
      "| E4M3         | 16         | EDEN     |                      3.34 |                0.00055 |\n",
      "| E8M0         | 32         | NO       |                      3.16 |                0.01145 |\n",
      "| E8M0         | 32         | SR       |                      2.58 |               -0.00001 |\n",
      "| E8M0         | 32         | EDEN     |                      2.63 |                0.00001 |\n"
     ]
    }
   ],
   "source": [
    "x = (torch.randn(2**20, 128, device=\"cuda\") * torch.logspace(0, 8, 2**20, base=2, device=\"cuda\").unsqueeze(1)).flatten()\n",
    "\n",
    "scale_dtype_group = [(\"fp32\", 128), (\"e4m3\", 16), (\"e8m0\", 32)]\n",
    "optimal_scale_override = {\n",
    "    \"eden\": {\n",
    "        \"fp32\": 0.96,\n",
    "        \"e4m3\": 0.93,\n",
    "        \"e8m0\": 0.91,\n",
    "    },\n",
    "    \"no\": {\n",
    "        \"fp32\": 0.96,\n",
    "        \"e4m3\": 0.93,\n",
    "        \"e8m0\": 0.84,\n",
    "    },\n",
    "    \"sr\": {\n",
    "        \"fp32\": 1.00,\n",
    "        \"e4m3\": 1.00,\n",
    "        \"e8m0\": 1.00,   \n",
    "    },\n",
    "}\n",
    "\n",
    "table_rows = []\n",
    "data = {}\n",
    "\n",
    "for (scale_dtype, group_dim) in scale_dtype_group:\n",
    "    for unbiased in [\"no\", \"sr\", \"eden\"]:\n",
    "        scale_override = optimal_scale_override[unbiased][scale_dtype]\n",
    "\n",
    "        \n",
    "        quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=group_dim, scale_dtype=scale_dtype, unbiased=unbiased, scale_override=scale_override)\n",
    "        dq = quantizer(x).view(-1, quantizer.hadamard_dim) @ quantizer.hadamard_matrix\n",
    "        ref = x.view(-1, quantizer.hadamard_dim)\n",
    "        quad_err = ((ref - dq).pow(2).sum(dim=-1) / ref.pow(2).sum(dim=-1)).mean()\n",
    "        eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "        magnitude_alignment = ((ref * dq).sum(dim=-1) / (ref * ref).sum(dim=-1)).mean().item()\n",
    "        \n",
    "        data[(group_dim, scale_dtype, unbiased)] = (eff_bitwidth, 1 - magnitude_alignment)\n",
    "        \n",
    "        table_rows.append(\n",
    "            (scale_dtype, group_dim, unbiased, eff_bitwidth, 1 - magnitude_alignment)\n",
    "        )\n",
    "\n",
    "# Print markdown table\n",
    "print(\"| Scales DType | Group Size | Unbiased | MSE, rate-distortion bits | Magnitude Misalignment |\")\n",
    "print(\"|--------------|------------|----------|---------------------------|------------------------|\")\n",
    "for row in table_rows:\n",
    "    print(f\"| {str(row[0].upper()):<12} | {str(row[1]):<10} | {str(row[2]).upper():<8} | {row[3]:>25.2f} | {row[4]:>22.5f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064f8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four_over_six=False,square=False: 3.395\n",
      "four_over_six=True,square=False: 3.524\n",
      "four_over_six=False,square=True: 3.167\n",
      "four_over_six=True,square=True: 3.168\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4096, 4096), device=\"cuda\")\n",
    "\n",
    "for square in [False, True]:\n",
    "    for four_over_six in [False, True]:\n",
    "        quantizer = Nvfp4Quantizer(square=square, four_over_six=four_over_six)\n",
    "        dq = quantizer(x)\n",
    "        quad_err = ((x - dq).pow(2).sum(dim=-1) / x.pow(2).sum(dim=-1)).mean()\n",
    "        eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "        magnitude_alignment = ((x * dq).sum(dim=-1) / (x * x).sum(dim=-1)).mean().item()\n",
    "        \n",
    "        print(f\"{four_over_six=},{square=}: {eff_bitwidth:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e707a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa38be4369a6436bafc067f7d2f89dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017aa4eade064e868f8dd0cff96b5b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 2.969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7779e74a67a46a78ec46d34cb707716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 3.967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57c299b554247d887b04242e8b77a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: 4.958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dd22868a4844debbf02d6796de79f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64: 5.929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003361c25364432983fea211a53aaf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256: 6.819\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4096, 2048), device=\"cuda\")\n",
    "y = torch.randn((1024, 2048), device=\"cuda\")\n",
    "\n",
    "unbiased = \"eden\"\n",
    "\n",
    "quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=16, scale_dtype=\"e4m3\", unbiased=unbiased, scale_override=optimal_scale_override[unbiased][\"e4m3\"], rerotate='signs', four_over_six=True)\n",
    "\n",
    "for acc_steps in tqdm([1, 4, 16, 64, 256]):\n",
    "    acc_prod = torch.zeros((x.shape[0], y.shape[0]), device=\"cuda\")\n",
    "    for step in trange(acc_steps, leave=False):\n",
    "        quantizer.re_randomize()\n",
    "        xq = quantizer(x)\n",
    "        yq = quantizer(y)\n",
    "        acc_prod += xq @ yq.T\n",
    "        \n",
    "    quad_err = (acc_prod / acc_steps - x @ y.T).pow(2).mean() / (x @ y.T).pow(2).mean()\n",
    "    eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "    print(f\"{acc_steps}: {eff_bitwidth:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0478ba12",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (1848078128.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    1: 2.840\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "1: 2.840\n",
    "4: 3.840\n",
    "16: 4.838\n",
    "64: 5.835\n",
    "256: 6.826"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

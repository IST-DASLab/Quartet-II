{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=8\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=8\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "from models.quantization.quantizers import QuestMXFP4Quantizer, AlbertTsengQuantizer, EdenSRQuantizer, IsolatedEdenQuantizer, QuestNvfp4Quantizer, Nvfp4Quantizer\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Scales DType | Group Size | Unbiased | MSE        | Rate, bits | Magnitude Misalignment |\n",
      "|--------------|------------|----------|------------|------------|------------------------|\n",
      "| E4M3         | 16         | NO       |        9.0 |       3.40 |                0.00790 |\n",
      "| E4M3         | 16         | SR       |       23.5 |       2.71 |                0.00002 |\n",
      "| E4M3         | 16         | EDEN     |        9.8 |       3.34 |                0.00055 |\n"
     ]
    }
   ],
   "source": [
    "x = (torch.randn(2**20, 128, device=\"cuda\") * torch.logspace(0, 8, 2**20, base=2, device=\"cuda\").unsqueeze(1)).flatten()\n",
    "\n",
    "scale_dtype_group = [\n",
    "    # (\"fp32\", 128),\n",
    "    (\"e4m3\", 16),\n",
    "    # (\"e8m0\", 32),\n",
    "]\n",
    "optimal_scale_override = {\n",
    "    \"eden\": {\n",
    "        \"fp32\": 0.96,\n",
    "        \"e4m3\": 0.93,\n",
    "        \"e8m0\": 0.91,\n",
    "    },\n",
    "    \"no\": {\n",
    "        \"fp32\": 0.96,\n",
    "        \"e4m3\": 0.93,\n",
    "        \"e8m0\": 0.84,\n",
    "    },\n",
    "    \"sr\": {\n",
    "        \"fp32\": 1.00,\n",
    "        \"e4m3\": 1.00,\n",
    "        \"e8m0\": 1.00,   \n",
    "    },\n",
    "}\n",
    "\n",
    "table_rows = []\n",
    "data = {}\n",
    "\n",
    "for (scale_dtype, group_dim) in scale_dtype_group:\n",
    "    for unbiased in [\"no\", \"sr\", \"eden\"]:\n",
    "        scale_override = optimal_scale_override[unbiased][scale_dtype]\n",
    "\n",
    "        \n",
    "        quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=group_dim, scale_dtype=scale_dtype, unbiased=unbiased, scale_override=scale_override, four_over_six=False)\n",
    "        dq = quantizer(x).view(-1, quantizer.hadamard_dim) @ quantizer.hadamard_matrix\n",
    "        ref = x.view(-1, quantizer.hadamard_dim)\n",
    "        quad_err = ((ref - dq).pow(2).sum(dim=-1) / ref.pow(2).sum(dim=-1)).mean()\n",
    "        eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "        magnitude_alignment = ((ref * dq).sum(dim=-1) / (ref * ref).sum(dim=-1)).mean().item()\n",
    "        \n",
    "        data[(group_dim, scale_dtype, unbiased)] = (eff_bitwidth, 1 - magnitude_alignment)\n",
    "        \n",
    "        table_rows.append(\n",
    "            (scale_dtype, group_dim, unbiased, quad_err, eff_bitwidth, 1 - magnitude_alignment)\n",
    "        )\n",
    "\n",
    "# Print markdown table\n",
    "print(\"| Scales DType | Group Size | Unbiased | MSE        | Rate, bits | Magnitude Misalignment |\")\n",
    "print(\"|--------------|------------|----------|------------|------------|------------------------|\")\n",
    "for row in table_rows:\n",
    "    print(f\"| {str(row[0].upper()):<12} | {str(row[1]):<10} | {str(row[2]).upper():<8} | {row[3] * 1e3:>10.1f} | {row[4]:>10.2f} | {row[5]:>22.5f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064f8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four_over_six=False,square=False: 9.0 3.394\n",
      "four_over_six=True,square=False: 7.6 3.524\n",
      "four_over_six=False,square=True: 12.4 3.168\n",
      "four_over_six=True,square=True: 12.4 3.169\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((8192, 8192), device=\"cuda\")\n",
    "\n",
    "for square in [False, True]:\n",
    "    for four_over_six in [False, True]:\n",
    "        quantizer = Nvfp4Quantizer(square=square, four_over_six=four_over_six)\n",
    "        dq = quantizer(x)\n",
    "        quad_err = ((x - dq).pow(2).sum(dim=-1) / x.pow(2).sum(dim=-1)).mean()\n",
    "        eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "        magnitude_alignment = ((x * dq).sum(dim=-1) / (x * x).sum(dim=-1)).mean().item()\n",
    "        \n",
    "        print(f\"{four_over_six=},{square=}: {quad_err*1e3:.1f} {eff_bitwidth:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e707a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f9deddadc347bcb6c36c59ff3b4406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363f3bd83b574a459c15d4a582fed2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 16.29 2.970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0282f74463fa4cbfb448a164f019bedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 4.08 3.968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b9a9df6ee94caca00566ca66cd8b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: 1.03 4.960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65f05f9c64148e89cc1b656c955ffd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64: 0.27 5.930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799a23ca7c324e448b212edc771d74a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256: 0.08 6.820\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4096, 4096), device=\"cuda\")\n",
    "y = torch.randn((4096, 4096), device=\"cuda\")\n",
    "\n",
    "unbiased = \"eden\"\n",
    "\n",
    "quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=16, scale_dtype=\"e4m3\", unbiased=unbiased, scale_override=optimal_scale_override[unbiased][\"e4m3\"], rerotate='signs', four_over_six=True)\n",
    "\n",
    "for acc_steps in tqdm([1, 4, 16, 64, 256]):\n",
    "    acc_prod = torch.zeros((x.shape[0], y.shape[0]), device=\"cuda\")\n",
    "    for step in trange(acc_steps, leave=False):\n",
    "        quantizer.re_randomize()\n",
    "        xq = quantizer(x)\n",
    "        yq = quantizer(y)\n",
    "        acc_prod += xq @ yq.T\n",
    "        \n",
    "    quad_err = (acc_prod / acc_steps - x @ y.T).pow(2).mean() / (x @ y.T).pow(2).mean()\n",
    "    eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "    print(f\"{acc_steps}: {quad_err * 1e3:.2f} {eff_bitwidth:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6764121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16.28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

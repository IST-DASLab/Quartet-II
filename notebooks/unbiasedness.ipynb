{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=9\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=9\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "from models.quantization.quantizers import QuestMXFP4Quantizer, AlbertTsengQuantizer, EdenSRQuantizer\n",
    "\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Scales DType | Group Size | Unbiased | MSE, rate-distortion bits | Magnitude Misalignment |\n",
      "|--------------|------------|----------|---------------------------|------------------------|\n",
      "| FP32         | 128        | NO       |                      3.20 |                0.00835 |\n",
      "| FP32         | 128        | SR       |                      2.69 |               -0.00000 |\n",
      "| FP32         | 128        | EDEN     |                      3.20 |                0.00000 |\n",
      "| E4M3         | 16         | NO       |                      3.28 |               -0.01119 |\n",
      "| E4M3         | 16         | SR       |                      2.70 |               -0.00001 |\n",
      "| E4M3         | 16         | EDEN     |                      3.25 |               -0.00125 |\n",
      "| E8M0         | 32         | NO       |                      3.10 |                0.00947 |\n",
      "| E8M0         | 32         | SR       |                      2.58 |               -0.00001 |\n",
      "| E8M0         | 32         | EDEN     |                      2.61 |                0.00050 |\n"
     ]
    }
   ],
   "source": [
    "x = (torch.randn(2**20, 128, device=\"cuda\") * torch.logspace(0, 10, 2**20, base=2, device=\"cuda\").unsqueeze(1)).flatten()\n",
    "\n",
    "scale_dtype_group = [(\"fp32\", 128), (\"e4m3\", 16), (\"e8m0\", 32)]\n",
    "\n",
    "table_rows = []\n",
    "data = {}\n",
    "\n",
    "for (scale_dtype, group_dim) in scale_dtype_group:\n",
    "    for unbiased in [\"no\", \"sr\", \"eden\"]:\n",
    "        quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=group_dim, scale_dtype=scale_dtype, unbiased=unbiased)\n",
    "        dq = quantizer(x).view(-1, quantizer.hadamard_dim) @ quantizer.hadamard_matrix\n",
    "        ref = x.view(-1, quantizer.hadamard_dim)\n",
    "        quad_err = ((ref - dq).pow(2).sum(dim=-1) / ref.pow(2).sum(dim=-1)).mean()\n",
    "        eff_bitwidth = (-torch.log2(quad_err) / 2).item()\n",
    "        magnitude_alignment = ((ref * dq).sum(dim=-1) / (ref * ref).sum(dim=-1)).abs().mean().item()\n",
    "        \n",
    "        data[(group_dim, scale_dtype, unbiased)] = (eff_bitwidth, 1 - magnitude_alignment)\n",
    "        \n",
    "        table_rows.append(\n",
    "            (scale_dtype, group_dim, unbiased, eff_bitwidth, 1 - magnitude_alignment)\n",
    "        )\n",
    "\n",
    "# Print markdown table\n",
    "print(\"| Scales DType | Group Size | Unbiased | MSE, rate-distortion bits | Magnitude Misalignment |\")\n",
    "print(\"|--------------|------------|----------|---------------------------|------------------------|\")\n",
    "for row in table_rows:\n",
    "    print(f\"| {str(row[0].upper()):<12} | {str(row[1]):<10} | {str(row[2]).upper():<8} | {row[3]:>25.2f} | {row[4]:>22.5f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68f665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16d1e4054964b8a939ae8198257a447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000f4c3690fe47e1a431de432a2b7551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.011094212532043457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c995b6c0034c67a91661efe6b7c9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : 0.0027771450113505125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f395710ab54a40589e59dcb4cfa0e578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 : 0.0006977391894906759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa72ccfff45444dcaed09fa275d9c322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 : 0.0001779412996256724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad95afefb14e93a7e59abe4893e174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 : 4.796600842382759e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb95595b318a4b9985486d59d26b18a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(accum_steps, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m     quantizer\u001b[38;5;241m.\u001b[39mre_randomize()\n\u001b[0;32m---> 10\u001b[0m     acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mquantizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, quantizer\u001b[38;5;241m.\u001b[39mhadamard_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m@\u001b[39m quantizer\u001b[38;5;241m.\u001b[39mhadamard_matrix)\u001b[38;5;241m.\u001b[39mview_as(x)\n\u001b[1;32m     11\u001b[0m err \u001b[38;5;241m=\u001b[39m (acc \u001b[38;5;241m/\u001b[39m accum_steps \u001b[38;5;241m-\u001b[39m x)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(accum_steps, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, err\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/micromamba/envs/llmb/lib/python3.10/site-packages/torch/nn/modules/module.py:1755\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/llmb/lib/python3.10/site-packages/torch/nn/modules/module.py:1766\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1764\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1765\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1768\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Quartet/notebooks/../src/models/quantization/quantizers/eden.py:187\u001b[0m, in \u001b[0;36mEdenSRQuantizer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m x_scaled \u001b[38;5;241m=\u001b[39m x_scaled\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhadamard_dim)\n\u001b[1;32m    186\u001b[0m num \u001b[38;5;241m=\u001b[39m (x_scaled \u001b[38;5;241m*\u001b[39m x_scaled)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 187\u001b[0m denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mx_scaled\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_fp4\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m correction \u001b[38;5;241m=\u001b[39m num \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m    189\u001b[0m correction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(correction\u001b[38;5;241m.\u001b[39misnan(), \u001b[38;5;241m1.0\u001b[39m, correction)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = (torch.randn(2**20, 128, device=\"cuda\") * torch.logspace(0, 16, 2**20, base=2, device=\"cuda\").unsqueeze(1)).flatten()\n",
    "\n",
    "quantizer = EdenSRQuantizer(hadamard_dim=128, group_dim=16, scale_dtype=\"e4m3\", unbiased=\"eden\", rerotate=\"signs\")\n",
    "\n",
    "for accum_steps in tqdm([1, 4, 16, 64, 256, 1024, 4096]):\n",
    "    acc = torch.zeros_like(x)\n",
    "\n",
    "    for _ in trange(accum_steps, leave=False):\n",
    "        quantizer.re_randomize()\n",
    "        acc += (quantizer(x).view(-1, quantizer.hadamard_matrix.shape[0]) @ quantizer.hadamard_matrix).view_as(x)\n",
    "    err = (acc / accum_steps - x).pow(2).sum() / x.pow(2).sum()\n",
    "    print(accum_steps, \":\", err.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94251d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_e4m3(x: torch.Tensor) -> torch.Tensor:\n",
    "    if (x > 448.001).any():\n",
    "        raise ValueError(f\"Can't SR overflowing tensor: {x.max().item()} > 448\")\n",
    "    x = torch.clamp(x, -447.99, 447.99)\n",
    "    \n",
    "    if x.isnan().any():\n",
    "        raise ValueError(\"x has NaNs\")\n",
    "    \n",
    "    q = x.to(torch.float8_e4m3fn)\n",
    "    nextdq = (q.view(torch.uint8) + 1).view(torch.float8_e4m3fn).float()\n",
    "    prevdq = (q.view(torch.uint8) - 1).view(torch.float8_e4m3fn).float()\n",
    "    dq = q.float()\n",
    "\n",
    "    low = torch.where(\n",
    "        dq > x,\n",
    "        prevdq,\n",
    "        dq,\n",
    "    )\n",
    "    \n",
    "    high = torch.where(\n",
    "        dq > x,\n",
    "        dq,\n",
    "        nextdq,\n",
    "    )\n",
    "    \n",
    "    return torch.where(\n",
    "        torch.bernoulli(\n",
    "            (x - low) / (high - low)\n",
    "        ) == 1.0,\n",
    "        high,\n",
    "        low,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab56273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448., 448.,\n",
       "        448., 448., 448., 448., 448., 448., 448., 448.], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((128,), device=\"cuda\") * 448.001\n",
    "sr_e4m3(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3431ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtn_fp4(x: torch.Tensor, grid: torch.Tensor) -> torch.Tensor:\n",
    "    inds = torch.bucketize(x, grid)\n",
    "\n",
    "    lo = torch.clamp(inds - 1, min=0, max=15)\n",
    "    hi = torch.clamp(inds,     min=0, max=15)\n",
    "\n",
    "    low = grid[lo]\n",
    "    high = grid[hi]\n",
    "\n",
    "    return torch.where(\n",
    "        (high - x) <= (x - low),\n",
    "        high,\n",
    "        low,\n",
    "    )\n",
    "    \n",
    "    \n",
    "grid = torch.tensor(\n",
    "    [-6.0, -4.0, -3.0, -2.0, -1.5, -1.0, -0.5, 0.0,\n",
    "    0.0,  0.5,  1.0,  1.5,  2.0,  3.0,  4.0, 6.0],\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df62fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0067, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.linspace(-6, 6, 1000, device=\"cuda\")\n",
    "\n",
    "q = rtn_fp4(t, grid)\n",
    "\n",
    "(t @ q) / (t @ t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134f757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
